{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1126bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5ccd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef294e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6f5250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47d0b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42840f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d3bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d067ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2983f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8268edcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ad2efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcfd2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2514b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cc78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10b470a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c64748d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0385e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f84c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4373b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f394efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 19ms/step - loss: 0.4000 - val_loss: 0.3448\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2517 - val_loss: 0.2039\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1425 - val_loss: 0.1092\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0750 - val_loss: 0.0597\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0450 - val_loss: 0.0415\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0380\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0368\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0350\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.0333\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0320\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0307\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0294\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0282\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0270\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0259\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0248\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0238\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0228\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0219\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0210\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0202\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0194\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0172\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,Y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c500f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9a9d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7674961574926608"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4a76a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20447236ec0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d21b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
